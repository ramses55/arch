{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89435568-e5a5-46c5-830a-94a88d58b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cec4cc36-b3e5-442f-90c5-ec595821616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['../Data/528.jpeg', '../Data/1084.jpg', '../Data/12146_И6125.jpg', '../Data/1753.jpeg', '../Data/12245_И6774.jpg',\n",
    "          '../Data/12145_И6666.jpg', '../Data/1038.jpg','../Data/12173_И4242.jpg', '../Data/20250805_101846.jpg',\n",
    "         '../Data/12156_И4559.jpg', '../Data/1038.jpg']\n",
    "\n",
    "\n",
    "image = images[4]\n",
    "\n",
    "\n",
    "template_path  = './ruler_template-h.png'\n",
    "\n",
    "template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd9bbded-384f-4884-9ad6-40bd6a35b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.ORB_create()\n",
    "\n",
    "kp1, des1 = sift.detectAndCompute(template, None)\n",
    "kp2, des2 = sift.detectAndCompute(img, None)\n",
    "\n",
    "template1 = cv2.drawKeypoints(template, kp1, template)\n",
    "img1 = cv2.drawKeypoints(img, kp2, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8bd3054-c84b-493c-9b6a-cec606003f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow(\"img\", img1)\n",
    "cv2.imshow(\"template\", template1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#plt.imshow(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9b045a9-f43f-49c3-be9b-b2540bd92616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good matches: 227\n",
      "CPU times: user 331 ms, sys: 26.3 ms, total: 357 ms\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load images\n",
    "template = cv2.imread(\"ruler_template-h.png\", cv2.IMREAD_GRAYSCALE)\n",
    "scene = cv2.imread(image, cv2.IMREAD_FastFeatureDetector_createGRAYSCALE)\n",
    "\n",
    "if template is None or scene is None:\n",
    "    raise IOError(\"Could not load images\")\n",
    "\n",
    "# Create ORB detector\n",
    "orb = cv2.ORB_create(\n",
    "    nfeatures=2000,\n",
    "    scaleFactor=1.2,\n",
    "    nlevels=8\n",
    ")\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "kp1, des1 = orb.detectAndCompute(template, None)\n",
    "kp2, des2 = orb.detectAndCompute(scene, None)\n",
    "\n",
    "# Create matcher (ORB uses binary descriptors → Hamming)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "# Match descriptors using KNN\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Apply Lowe's ratio test\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "print(f\"Good matches: {len(good_matches)}\")\n",
    "\n",
    "# Draw matches\n",
    "matched_img = cv2.drawMatches(\n",
    "    template, kp1,\n",
    "    scene, kp2,\n",
    "    good_matches, None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    ")\n",
    "\n",
    "cv2.imshow(\"ORB Matches\", matched_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ---- Optional: Locate template using homography ----\n",
    "if len(good_matches) > 10:\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    if H is not None:\n",
    "        h, w = template.shape\n",
    "        corners = np.float32([[0,0], [w,0], [w,h], [0,h]]).reshape(-1,1,2)\n",
    "        projected = cv2.perspectiveTransform(corners, H)\n",
    "\n",
    "        scene_color = cv2.cvtColor(scene, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.polylines(scene_color, [np.int32(projected)], True, (0,255,0), 3)\n",
    "\n",
    "        #cv2.imshow(\"Detected Template\", scene_color)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e460a3-033a-4d05-8425-bb45556a5232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
